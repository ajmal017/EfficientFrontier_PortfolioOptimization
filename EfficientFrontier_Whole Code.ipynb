{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPortfolioOpt\n",
    "pip install pandas_datareader\n",
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Tickers as Identified by Global X-funds in their Fin-tech ETF\n",
    "tk = pd.read_csv(\"/home/rampage/Downloads/global-x-cloud-computing-etf_full-holdings_20191008.csv\")\n",
    "tk.columns = ('Global X Cloud Computing ETF', 'Name', 'Price', 'Shares Held', 'Market Value')\n",
    "tk = tk.drop([0,1], axis = 0)\n",
    "companies = pd.DataFrame(tk['Name'].unique()).reset_index()[0]\n",
    "start = datetime.datetime(2014,1,1)\n",
    "end = datetime.datetime(2019,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a range of dates over which to find the weights\n",
    "dates = []\n",
    "date = datetime.datetime(2018,7,16)\n",
    "for i in range(52):\n",
    "    date += datetime.timedelta(days = 7) \n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to find ticker from company name\n",
    "import requests\n",
    "def get_symbol(symbol):\n",
    "    url = \"http://d.yimg.com/autoc.finance.yahoo.com/autoc?query={}&region=1&lang=en\".format(symbol)\n",
    "\n",
    "    result = requests.get(url).json()\n",
    "\n",
    "    for x in result['ResultSet']['Result']:\n",
    "        return x['symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Unnecessary words from Company titles to find corresponding ticker values\n",
    "stopwords = {'INC', 'Holding',' CORP', 'INC-CL A', 'INC-CLASS A', 'LTD', 'GRP-ADR','-', 'CLASS', 'A','-CL A','INC-CLASS','CORP','INC-ADR','INC-CL','TRUST', 'CASH' }\n",
    "title =[]\n",
    "for i in companies:\n",
    "    rs = [word for word in i.split() if word not in stopwords]\n",
    "    rs = ' '.join(rs)\n",
    "    title.append(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Tickers from company titles\n",
    "tickers = []\n",
    "for i in title:\n",
    "    com = get_symbol(i)\n",
    "    tickers.append(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Close function to get daily close prices of the stocks\n",
    "def close(tickers, startdate, enddate):\n",
    "    def data(ticker):\n",
    "        try:\n",
    "            return (pdr.get_data_yahoo(ticker, start = startdate, end = enddate)['Adj Close']).rename(ticker)\n",
    "        except:\n",
    "            pass\n",
    "    datas = map(data, tickers)\n",
    "    return(pd.concat(datas, axis = 1))\n",
    "dataset = close(tickers, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning data to remove all empty rows\n",
    "all_data = dataset.dropna(axis = 0, thresh = 3)\n",
    "all_data = all_data.fillna(method='bfill')\n",
    "\n",
    "#mean and covariance\n",
    "mean = expected_returns.mean_historical_return(all_data)\n",
    "sd = risk_models.sample_cov(all_data)\n",
    "\n",
    "e_frontier = EfficientFrontier(mean, sd)\n",
    "raw_weights = e_frontier.max_sharpe()\n",
    "cleaned_weights = e_frontier.clean_weights()\n",
    "e_frontier.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Big Lopp for getting efficient weights each of 52 weeks\n",
    "alldata = []\n",
    "#Getting Ajd Close for all the tickers\n",
    "for i in dates:\n",
    "    end = i\n",
    "    dataset = close(tickers, start, end)\n",
    "    all_data = dataset.dropna(axis = 0, thresh = 3)\n",
    "    all_data = all_data.fillna(method='bfill')\n",
    "\n",
    "#mean and covariance\n",
    "    mu = expected_returns.mean_historical_return(all_data)\n",
    "    S = risk_models.sample_cov(all_data)\n",
    "    \n",
    "    ef = EfficientFrontier(mu, S)\n",
    "\n",
    "    raw_weights = ef.max_sharpe()\n",
    "    cleaned_weights = ef.clean_weights()\n",
    "    \n",
    "    f_dat = pd.DataFrame(cleaned_weights, index=[0])\n",
    "\n",
    "\n",
    "    ret = ef.portfolio_performance(verbose=False)[0]\n",
    "    vol = ef.portfolio_performance(verbose=False)[1]\n",
    "    sharp = ef.portfolio_performance(verbose=False)[2]\n",
    "\n",
    "    f_dat['Return'] = ret\n",
    "    f_dat['Volatility'] = vol\n",
    "    f_dat['Sharpe.Ratio'] = sharp\n",
    "    \n",
    "    alldata.append(f_dat)\n",
    "    print(f_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregating the list entries in a dataframe\n",
    "mod_data = []\n",
    "for i in range(0,len(alldata)):\n",
    "    new = alldata[i]\n",
    "    mod_data.append(new)\n",
    "mod_data = pd.concat(mod_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data.to_csv('out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
